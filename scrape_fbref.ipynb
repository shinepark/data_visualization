{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be93aa3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"/Users/shinepark/anaconda3/bin/python\"\n  * The NumPy version is: \"1.24.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-darwin.so, 0x0002): Library not loaded: '@rpath/libopenblas.0.dylib'\n  Referenced from: '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-darwin.so'\n  Reason: tried: '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/../../../../libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/../../../../libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/bin/../lib/libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/bin/../lib/libopenblas.0.dylib' (no such file), '/usr/local/lib/libopenblas.0.dylib' (no such file), '/usr/lib/libopenblas.0.dylib' (no such file)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup \u001b[38;5;28;01mas\u001b[39;00m soup\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/__init__.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"/Users/shinepark/anaconda3/bin/python\"\n  * The NumPy version is: \"1.24.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-darwin.so, 0x0002): Library not loaded: '@rpath/libopenblas.0.dylib'\n  Referenced from: '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-darwin.so'\n  Reason: tried: '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/../../../../libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/lib/python3.11/site-packages/numpy/core/../../../../libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/bin/../lib/libopenblas.0.dylib' (no such file), '/Users/shinepark/anaconda3/bin/../lib/libopenblas.0.dylib' (no such file), '/usr/local/lib/libopenblas.0.dylib' (no such file), '/usr/lib/libopenblas.0.dylib' (no such file)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from functools import reduce\n",
    "import sys\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "\n",
    "def get_data_info():\n",
    "    # all possible leagues and seasons\n",
    "    leagues = [\"FA Women's Super League\"]\n",
    "    seasons = ['2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
    "    \n",
    "    while True:\n",
    "        # select league \n",
    "        league = input(\"Select League (FA Women's Super League): \")\n",
    "        \n",
    "        # check if input valid\n",
    "        if league not in leagues:\n",
    "            print('League not valid, try again')\n",
    "            continue\n",
    "            \n",
    "        # assign url names and id's\n",
    "        if league == \"FA Women's Super League\":\n",
    "            league = \"FA-Women's-Super-League\"\n",
    "            league_id = '189'\n",
    "        '''\n",
    "        if league == 'La Liga':\n",
    "            league = 'La-Liga'\n",
    "            league_id = '12'\n",
    "\n",
    "        if league == 'Serie A':\n",
    "            league = 'Serie-A'\n",
    "            league_id = '11'\n",
    "\n",
    "        if league == 'Ligue 1':\n",
    "            league = 'Ligue-1'\n",
    "            league_id = '13'\n",
    "\n",
    "        if league == 'Bundesliga':\n",
    "            league = 'Bundesliga'\n",
    "            league_id = '20'\n",
    "        '''\n",
    "        break\n",
    "            \n",
    "    while True: \n",
    "        # select season \n",
    "        season = input('Select Season (2020-2021, 2021-2022, 2022-2023, 2023-2024, 2024-2025): ')\n",
    "        \n",
    "        # check if input valid\n",
    "        if season not in seasons:\n",
    "            print('Season not valid, try again')\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    url = f'https://fbref.com/en/comps/{league_id}/{season}/schedule/{season}-{league}-Scores-and-Fixtures'\n",
    "    return url, league, season\n",
    "\n",
    "\n",
    "def get_fixture_data(url, league, season):\n",
    "    print('Getting fixture data...')\n",
    "    # create empty data frame and access all tables in url\n",
    "    fixturedata = pd.DataFrame([])\n",
    "    tables = pd.read_html(url)\n",
    "    \n",
    "    # get fixtures\n",
    "    fixtures = tables[0][['Wk', 'Day', 'Date', 'Time', 'Home', 'Away', 'xG', 'xG.1', 'Score']].dropna()\n",
    "    fixtures['season'] = url.split('/')[6]\n",
    "    fixturedata = pd.concat([fixturedata,fixtures])\n",
    "    \n",
    "    # assign id for each game\n",
    "    fixturedata[\"game_id\"] = fixturedata.index\n",
    "    \n",
    "    # export to csv file\n",
    "    fixturedata.reset_index(drop=True).to_csv(f'{league.lower()}_{season.lower()}_fixture_data.csv', \n",
    "        header=True, index=False, mode='w')\n",
    "    print('Fixture data collected...')\n",
    "\n",
    "\n",
    "def get_match_links(url, league):   \n",
    "    print('Getting player data...')\n",
    "    # access and download content from url containing all fixture links    \n",
    "    match_links = []\n",
    "    html = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    links = soup(html.content, \"html.parser\").find_all('a')\n",
    "    \n",
    "    # filter list to return only needed links\n",
    "    key_words_good = ['/en/matches/', f'{league}']\n",
    "    for l in links:\n",
    "        href = l.get('href', '')\n",
    "        if all(x in href for x in key_words_good):\n",
    "            if 'https://fbref.com' + href not in match_links:                 \n",
    "                match_links.append('https://fbref.com' + href)\n",
    "    return match_links\n",
    "\n",
    "\n",
    "def player_data(match_links, league, season):\n",
    "    # loop through all fixtures\n",
    "    player_data = pd.DataFrame([])\n",
    "    for count, link in enumerate(match_links):\n",
    "        try:\n",
    "            tables = pd.read_html(link)\n",
    "            for table in tables:\n",
    "                try:\n",
    "                    table.columns = table.columns.droplevel()\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            # get player data\n",
    "            def get_team_1_player_data():\n",
    "                # outfield and goal keeper data stored in seperate tables \n",
    "                data_frames = [tables[3], tables[9]]\n",
    "                \n",
    "                # merge outfield and goal keeper data\n",
    "                df = reduce(lambda left, right: pd.merge(left, right, \n",
    "                    on=['Player', 'Nation', 'Age', 'Min'], how='outer'), data_frames).iloc[:-1]\n",
    "                \n",
    "                # assign a home or away value\n",
    "                return df.assign(home=1, game_id=count)\n",
    "\n",
    "            # get second teams  player data        \n",
    "            def get_team_2_player_data():\n",
    "                data_frames = [tables[10], tables[16]]\n",
    "                df = reduce(lambda left, right: pd.merge(left, right,\n",
    "                    on=['Player', 'Nation', 'Age', 'Min'], how='outer'), data_frames).iloc[:-1]\n",
    "                return df.assign(home=0, game_id=count)\n",
    "\n",
    "            # combine both team data and export all match data to csv\n",
    "            t1 = get_team_1_player_data()\n",
    "            t2 = get_team_2_player_data()\n",
    "            player_data = pd.concat([player_data, pd.concat([t1,t2]).reset_index()])\n",
    "            \n",
    "            print(f'{count+1}/{len(match_links)} matches collected')\n",
    "            player_data.to_csv(f'{league.lower()}_{season.lower()}_player_data.csv', \n",
    "                header=True, index=False, mode='w')\n",
    "        except:\n",
    "            print(f'{link}: error')\n",
    "        # sleep for 3 seconds after every game to avoid IP being blocked\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "# main function\n",
    "def main(): \n",
    "    url, league, season = get_data_info()\n",
    "    get_fixture_data(url, league, season)\n",
    "    match_links = get_match_links(url, league)\n",
    "    player_data(match_links, league, season)\n",
    "\n",
    "    # checks if user wants to collect more data\n",
    "    print('Data collected!')\n",
    "    while True:\n",
    "        answer = input('Do you want to collect more data? (yes/no): ')\n",
    "        if answer == 'yes':\n",
    "            main()\n",
    "        if answer == 'no':\n",
    "            sys.exit()\n",
    "        else:\n",
    "            print('Answer not valid')\n",
    "            continue\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except HTTPError:\n",
    "        print('The website refused access, try again later')\n",
    "        time.sleep(5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
